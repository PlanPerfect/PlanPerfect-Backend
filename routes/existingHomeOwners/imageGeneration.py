"""
Image Generation API

This file handles image generation using img2img Stable Diffusion
It takes a input image and selected styles by the user,
generates a text prompt using a LLM and then runs Stable Diffusion to generate
a new image

Workflow:
1. Receives input image and style preferences from frontend
2. Uses LLM to generate a prompt for Stable Diffusion based on the selected style(s)
3. Runs Stable Diffusion img2img to generate a new image
4. Uploads generated image to Cloudinary
5. Returns the Cloudinary URL in the response

This API is used by the image generation feature in the frontend

Workflow Design Notes:
- Stable Diffusion parameters are fixed to balance image quality, realism and runtime
- img2img is used to preserve room layout and structure, instead of text-to-image
- Additional checks are added to ensure that LLM output is valid
- Original aspect ratio is preserved throughout the generation process
- Images are stored in Cloudinary for persistent cloud storage
"""

from fastapi import APIRouter, Form, HTTPException
from fastapi.concurrency import run_in_threadpool
from PIL import Image
import uuid
import torch
import io
import tempfile
import os
import requests
from Services.StableDiffusion import pipe
from Services.LLMGemini import generate_sd_prompt
from Services.FileManager import FileManager

use_cuda = torch.cuda.is_available()

def resize_to_target_with_aspect_ratio(image: Image.Image, target_size: int = 512):
    """
    Resize image to target size while maintaining aspect ratio.
    The longest side will be resized to target_size, and the shorter side
    will be scaled proportionally. Both dimensions will be multiples of 8
    (required by Stable Diffusion).

    Args:
        image: PIL Image to resize
        target_size: target size for the longest dimension

    Returns:
        Resized PIL Image with preserved aspect ratio
    """
    w, h = image.size
    aspect_ratio = w / h

    if w >= h:
        # Landscape or square
        new_w = target_size
        new_h = int(target_size / aspect_ratio)
    else:
        # Portrait
        new_h = target_size
        new_w = int(target_size * aspect_ratio)

    # Round to nearest multiple of 8 (SD requirement)
    new_w = max(8, (new_w // 8) * 8)
    new_h = max(8, (new_h // 8) * 8)

    # Ensure both dimensions are at least 384 but maintain aspect ratio
    if new_w < 384 or new_h < 384:
        scale = max(384 / new_w, 384 / new_h)
        new_w = int(new_w * scale)
        new_h = int(new_h * scale)
        # Round again to multiple of 8
        new_w = (new_w // 8) * 8
        new_h = (new_h // 8) * 8
    
    return image.resize((new_w, new_h), Image.LANCZOS)


def choose_base_resolution(image: Image.Image):
    """
    Decide a safe base resolution for SD img2img
    based on input image size.
    """
    w, h = image.size
    min_side = min(w, h)

    if min_side >= 768:
        base = 512
    elif min_side >= 512:
        base = 448
    else:
        base = 384
    return base

def run_stable_diffusion(init_image: Image.Image, prompt: str):
    """
    Run img2img Stable Diffusion with predefined generation parameters

    Args:
        init_image: room image uploaded by user (with preserved aspect ratio)
        prompt: text promp generated by LLM based on user selected style(s)

    Returns:
        Generated image based on the input image and prompt

    Generation Parameters (strength, guidance_scale) Explanation:
    These parameter values were chosen through experimentation to balance
    generation time, image quality, realism for interior design and level of style influence.

    strength is set to 0.45 to allow significant style changes while preserving room layout.
    guidance_scale of 7.5 increases adherence to the prompt.
    Negative prompt is fixed, as LLM's negative prompts are often low quality, describing
    generic bad image features. Hence, using a higher quality fixed negative prompt
    would yield higher image quality.
    """
    return pipe(
        prompt=prompt + ", real interior photograph, natural proportions",
        negative_prompt=(
            "cartoon, anime, illustration, painting, sketch, lowres, blurry, "
            "distorted geometry, warped walls, bent lines, duplicated furniture, "
            "bad perspective, fisheye distortion, oversharpened, noise, jpeg artifacts"
        ),
        image=init_image,
        strength=0.45,
        guidance_scale=8,
        num_inference_steps=25
    ).images[0]


class UploadFileAdapter:
    """Adapter to make image bytes compatible with FileManager's expected UploadFile interface"""
    def __init__(self, file_content: bytes, filename: str):
        self.file = io.BytesIO(file_content)
        self.filename = filename


router = APIRouter(prefix="/image", tags=["Image Generation"])

@router.post("/generate")
async def generate_image(
    file_id: str = Form(...),
    styles: str = Form(...),
):
    """
    Generate a new room design using Stable Diffusion.

    Args:
        file_id: Cloudinary file_id from the classification step
        styles: Comma-separated string of selected interior design styles

    Returns:
        JSON with generated image URL, file_id, and filename
    """
    tmp_file_path = None
    try:
        # ================================
        # Download image from Cloudinary
        # ================================
        # Get the image URL from Cloudinary using the file_id
        image_url = FileManager.get_optimized_url(file_id)

        # Download the image to a temporary file
        import requests
        response = requests.get(image_url)
        response.raise_for_status()

        suffix = '.png'
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:
            tmp_file.write(response.content)
            tmp_file_path = tmp_file.name

        init_image = Image.open(tmp_file_path).convert("RGB")

        # ================================
        # Generate prompt using LLM with retry logic
        # ================================
        max_retries = 3
        parsed = None

        for attempt in range(max_retries):
            try:
                llm_response = generate_sd_prompt(styles)
                parsed = llm_response
                if "prompt" not in parsed:
                    raise ValueError("Missing required fields in JSON")
                break
            except ValueError as e:
                print(f"Attempt {attempt + 1} failed: {str(e)}")
                if attempt == max_retries - 1:
                    # Use fallback prompts
                    print("All retries failed, using fallback prompts")
                    parsed = {
                        "prompt": f"{styles}, detailed, high quality, professional",
                        "negative": "cartoon, anime, illustration, painting, sketch, lowres, blurry, "
                                    "distorted geometry, warped walls, bent lines, duplicated furniture, "
                                    "bad perspective, fisheye distortion, oversharpened, noise, jpeg artifacts"
                    }
                    break

        prompt = parsed["prompt"]

        # Ensure prompts aren't empty
        if not prompt or prompt.strip() == "":
            prompt = "detailed, high quality, professional photograph"

        # ================================
        # Run Stable Diffusion
        # ================================
        # Clear GPU cache before generation, helps with faster generation of images
        if use_cuda:
            torch.cuda.empty_cache()

        base_size = choose_base_resolution(init_image)

        # Resize while maintaining aspect ratio
        init_image = resize_to_target_with_aspect_ratio(init_image, base_size)

        # Run Stable Diffusion img2img
        result = await run_in_threadpool(run_stable_diffusion, init_image, prompt)

        # Upscale 2x while maintaining aspect ratio
        hires_image = result.resize(
            (result.width * 2, result.height * 2),
            Image.LANCZOS
        )

        hires_result = await run_in_threadpool(
            lambda: pipe(
                prompt=prompt + ", ultra detailed interior photograph, sharp focus, architectural photography",
                negative_prompt=(
                    "cartoon, anime, illustration, distorted geometry, warped walls, "
                    "duplicated furniture, bad perspective"
                ),
                image=hires_image,
                strength=0.30,
                guidance_scale=7.5,
                num_inference_steps=30
            ).images[0]
        )

        # ================================
        # Upload to Cloudinary
        # ================================
        # Convert PIL Image to bytes for Cloudinary upload
        img_byte_arr = io.BytesIO()
        hires_result.save(img_byte_arr, format='PNG', quality=95)
        img_byte_arr.seek(0)

        # Create adapter for FileManager
        file_adapter = UploadFileAdapter(
            img_byte_arr.getvalue(),
            f"generated_design_{uuid.uuid4()}.png"
        )

        # Upload to Cloudinary
        cloudinary_result = FileManager.store_file(
            file=file_adapter,
            subfolder="Generated Designs"
        )

        # ================================
        # Clean up temporary file
        # ================================
        if tmp_file_path and os.path.exists(tmp_file_path):
            os.unlink(tmp_file_path)

        # ================================
        # Return Cloudinary URL and file_id
        # ================================
        return {
            "url": cloudinary_result["url"],
            "file_id": cloudinary_result["file_id"],
            "filename": cloudinary_result["filename"]
        }

    except Exception as e:
        # ================================
        # Error handling and cleanup
        # ================================
        if tmp_file_path and os.path.exists(tmp_file_path):
            try:
                os.unlink(tmp_file_path)
            except:
                pass

        print(f"Error in generate_image: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))